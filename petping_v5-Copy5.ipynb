{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\MUICT\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m   \u001b[1;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ae2b0c542ba0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 83\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\MUICT\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference for Building model part: https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>...</th>\n",
       "      <th>c_16</th>\n",
       "      <th>c_17</th>\n",
       "      <th>c_18</th>\n",
       "      <th>c_19</th>\n",
       "      <th>c_20</th>\n",
       "      <th>c_21</th>\n",
       "      <th>c_22</th>\n",
       "      <th>c_23</th>\n",
       "      <th>c_24</th>\n",
       "      <th>c_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  d_1  d_2  d_3  d_4  d_5  d_6  d_7  d_8  d_9  ...  c_16  c_17  c_18  \\\n",
       "0       1    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
       "1       2    0    1    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "2       3    0    1    0    1    0    0    0    0    0  ...     0     0     0   \n",
       "3       4    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "4       5    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "..    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "304   305    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "305   306    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
       "306   307    0    0    0    0    0    1    0    0    0  ...     0     0     0   \n",
       "307   308    1    0    0    0    0    1    0    0    0  ...     0     0     0   \n",
       "308   309    0    0    0    1    1    1    1    1    0  ...     0     0     0   \n",
       "\n",
       "     c_19  c_20  c_21  c_22  c_23  c_24  c_25  \n",
       "0       0     0     0     0     0     0     0  \n",
       "1       0     0     0     0     0     0     0  \n",
       "2       0     0     0     0     0     0     0  \n",
       "3       0     0     0     0     0     0     0  \n",
       "4       0     0     0     0     0     0     0  \n",
       "..    ...   ...   ...   ...   ...   ...   ...  \n",
       "304     0     0     0     0     0     0     0  \n",
       "305     0     0     0     0     0     0     1  \n",
       "306     0     0     0     0     0     0     0  \n",
       "307     0     0     0     0     0     0     0  \n",
       "308     0     0     0     0     0     0     0  \n",
       "\n",
       "[309 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the .CSV file\n",
    "\n",
    "item_matrix = pd.read_csv('db_test_2803.csv')\n",
    "item_matrix = item_matrix.drop(columns=['user'])\n",
    "item_matrix = item_matrix.astype(int)\n",
    "item_matrix.fillna(0)\n",
    "\n",
    "user_item_matrix = pd.read_csv('db_test_2803.csv')\n",
    "user_item_matrix = user_item_matrix.astype(int)\n",
    "user_item_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function named get_cosine() as Aj. Ananta comment\n",
    "\n",
    "def get_cosine(vec1,vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum ([vec1[x] * vec2[x] for x in intersection])\n",
    "    \n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    \n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator)/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>...</th>\n",
       "      <th>c_16</th>\n",
       "      <th>c_17</th>\n",
       "      <th>c_18</th>\n",
       "      <th>c_19</th>\n",
       "      <th>c_20</th>\n",
       "      <th>c_21</th>\n",
       "      <th>c_22</th>\n",
       "      <th>c_23</th>\n",
       "      <th>c_24</th>\n",
       "      <th>c_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     d_1  d_2  d_3  d_4  d_5  d_6  d_7  d_8  d_9 d_10  ... c_16 c_17 c_18  \\\n",
       "d_1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "d_2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "d_3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "d_4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "d_5  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "\n",
       "    c_19 c_20 c_21 c_22 c_23 c_24 c_25  \n",
       "d_1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "d_2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "d_3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "d_4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "d_5  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new DataFrame matrix for keeping the cosine similarity value\n",
    "\n",
    "item_item_matrix = pd.DataFrame(index=item_matrix.columns,columns=item_matrix.columns)\n",
    "item_item_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>...</th>\n",
       "      <th>c_16</th>\n",
       "      <th>c_17</th>\n",
       "      <th>c_18</th>\n",
       "      <th>c_19</th>\n",
       "      <th>c_20</th>\n",
       "      <th>c_21</th>\n",
       "      <th>c_22</th>\n",
       "      <th>c_23</th>\n",
       "      <th>c_24</th>\n",
       "      <th>c_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.32051</td>\n",
       "      <td>0.373773</td>\n",
       "      <td>0.348991</td>\n",
       "      <td>0.575829</td>\n",
       "      <td>0.608781</td>\n",
       "      <td>0.367109</td>\n",
       "      <td>0.473249</td>\n",
       "      <td>0.602475</td>\n",
       "      <td>0.38949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162221</td>\n",
       "      <td>0.191943</td>\n",
       "      <td>0.169278</td>\n",
       "      <td>0.191346</td>\n",
       "      <td>0.177705</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.150619</td>\n",
       "      <td>0.187317</td>\n",
       "      <td>0.266557</td>\n",
       "      <td>0.210866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_2</th>\n",
       "      <td>0.32051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45257</td>\n",
       "      <td>0.484706</td>\n",
       "      <td>0.352517</td>\n",
       "      <td>0.316862</td>\n",
       "      <td>0.30572</td>\n",
       "      <td>0.432291</td>\n",
       "      <td>0.305741</td>\n",
       "      <td>0.47061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131717</td>\n",
       "      <td>0.185535</td>\n",
       "      <td>0.147264</td>\n",
       "      <td>0.194206</td>\n",
       "      <td>0.180361</td>\n",
       "      <td>0.249286</td>\n",
       "      <td>0.142679</td>\n",
       "      <td>0.211241</td>\n",
       "      <td>0.240481</td>\n",
       "      <td>0.183444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_3</th>\n",
       "      <td>0.373773</td>\n",
       "      <td>0.45257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494312</td>\n",
       "      <td>0.430458</td>\n",
       "      <td>0.280056</td>\n",
       "      <td>0.52775</td>\n",
       "      <td>0.495284</td>\n",
       "      <td>0.40534</td>\n",
       "      <td>0.499134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266789</td>\n",
       "      <td>0.20498</td>\n",
       "      <td>0.235008</td>\n",
       "      <td>0.250319</td>\n",
       "      <td>0.265684</td>\n",
       "      <td>0.334428</td>\n",
       "      <td>0.247708</td>\n",
       "      <td>0.23338</td>\n",
       "      <td>0.309965</td>\n",
       "      <td>0.270226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_4</th>\n",
       "      <td>0.348991</td>\n",
       "      <td>0.484706</td>\n",
       "      <td>0.494312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.401918</td>\n",
       "      <td>0.294174</td>\n",
       "      <td>0.45334</td>\n",
       "      <td>0.495479</td>\n",
       "      <td>0.420517</td>\n",
       "      <td>0.466041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226455</td>\n",
       "      <td>0.248807</td>\n",
       "      <td>0.270064</td>\n",
       "      <td>0.233723</td>\n",
       "      <td>0.206725</td>\n",
       "      <td>0.257151</td>\n",
       "      <td>0.25231</td>\n",
       "      <td>0.261488</td>\n",
       "      <td>0.268742</td>\n",
       "      <td>0.189233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_5</th>\n",
       "      <td>0.575829</td>\n",
       "      <td>0.352517</td>\n",
       "      <td>0.430458</td>\n",
       "      <td>0.401918</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48795</td>\n",
       "      <td>0.500216</td>\n",
       "      <td>0.517769</td>\n",
       "      <td>0.596377</td>\n",
       "      <td>0.492805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135225</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.151186</td>\n",
       "      <td>0.174456</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>0.188329</td>\n",
       "      <td>0.22771</td>\n",
       "      <td>0.277746</td>\n",
       "      <td>0.219718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_6</th>\n",
       "      <td>0.608781</td>\n",
       "      <td>0.316862</td>\n",
       "      <td>0.280056</td>\n",
       "      <td>0.294174</td>\n",
       "      <td>0.48795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351763</td>\n",
       "      <td>0.463184</td>\n",
       "      <td>0.562859</td>\n",
       "      <td>0.420813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173205</td>\n",
       "      <td>0.219578</td>\n",
       "      <td>0.150616</td>\n",
       "      <td>0.212814</td>\n",
       "      <td>0.237171</td>\n",
       "      <td>0.210732</td>\n",
       "      <td>0.160817</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.210819</td>\n",
       "      <td>0.160817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_7</th>\n",
       "      <td>0.367109</td>\n",
       "      <td>0.30572</td>\n",
       "      <td>0.52775</td>\n",
       "      <td>0.45334</td>\n",
       "      <td>0.500216</td>\n",
       "      <td>0.351763</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533229</td>\n",
       "      <td>0.42023</td>\n",
       "      <td>0.597081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243709</td>\n",
       "      <td>0.205971</td>\n",
       "      <td>0.2076</td>\n",
       "      <td>0.205331</td>\n",
       "      <td>0.222475</td>\n",
       "      <td>0.254152</td>\n",
       "      <td>0.258603</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.286039</td>\n",
       "      <td>0.193952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_8</th>\n",
       "      <td>0.473249</td>\n",
       "      <td>0.432291</td>\n",
       "      <td>0.495284</td>\n",
       "      <td>0.495479</td>\n",
       "      <td>0.517769</td>\n",
       "      <td>0.463184</td>\n",
       "      <td>0.533229</td>\n",
       "      <td>0</td>\n",
       "      <td>0.568815</td>\n",
       "      <td>0.600375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233384</td>\n",
       "      <td>0.221901</td>\n",
       "      <td>0.260931</td>\n",
       "      <td>0.19356</td>\n",
       "      <td>0.266312</td>\n",
       "      <td>0.283949</td>\n",
       "      <td>0.297951</td>\n",
       "      <td>0.280717</td>\n",
       "      <td>0.319574</td>\n",
       "      <td>0.189605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_9</th>\n",
       "      <td>0.602475</td>\n",
       "      <td>0.305741</td>\n",
       "      <td>0.40534</td>\n",
       "      <td>0.420517</td>\n",
       "      <td>0.596377</td>\n",
       "      <td>0.562859</td>\n",
       "      <td>0.42023</td>\n",
       "      <td>0.568815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185695</td>\n",
       "      <td>0.219718</td>\n",
       "      <td>0.166091</td>\n",
       "      <td>0.246414</td>\n",
       "      <td>0.203419</td>\n",
       "      <td>0.210866</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.214423</td>\n",
       "      <td>0.203419</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_10</th>\n",
       "      <td>0.38949</td>\n",
       "      <td>0.47061</td>\n",
       "      <td>0.499134</td>\n",
       "      <td>0.466041</td>\n",
       "      <td>0.492805</td>\n",
       "      <td>0.420813</td>\n",
       "      <td>0.597081</td>\n",
       "      <td>0.600375</td>\n",
       "      <td>0.54139</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.20292</td>\n",
       "      <td>0.178958</td>\n",
       "      <td>0.177003</td>\n",
       "      <td>0.219179</td>\n",
       "      <td>0.222566</td>\n",
       "      <td>0.191079</td>\n",
       "      <td>0.264039</td>\n",
       "      <td>0.219179</td>\n",
       "      <td>0.159232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_11</th>\n",
       "      <td>0.390007</td>\n",
       "      <td>0.341506</td>\n",
       "      <td>0.497346</td>\n",
       "      <td>0.51241</td>\n",
       "      <td>0.430282</td>\n",
       "      <td>0.387836</td>\n",
       "      <td>0.541603</td>\n",
       "      <td>0.515711</td>\n",
       "      <td>0.446442</td>\n",
       "      <td>0.582086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19799</td>\n",
       "      <td>0.215141</td>\n",
       "      <td>0.189737</td>\n",
       "      <td>0.229366</td>\n",
       "      <td>0.232379</td>\n",
       "      <td>0.183533</td>\n",
       "      <td>0.21009</td>\n",
       "      <td>0.190516</td>\n",
       "      <td>0.180739</td>\n",
       "      <td>0.183829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_12</th>\n",
       "      <td>0.530732</td>\n",
       "      <td>0.401359</td>\n",
       "      <td>0.443422</td>\n",
       "      <td>0.414023</td>\n",
       "      <td>0.61807</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.502519</td>\n",
       "      <td>0.533363</td>\n",
       "      <td>0.643268</td>\n",
       "      <td>0.627093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15396</td>\n",
       "      <td>0.22771</td>\n",
       "      <td>0.200821</td>\n",
       "      <td>0.170251</td>\n",
       "      <td>0.175682</td>\n",
       "      <td>0.218537</td>\n",
       "      <td>0.214423</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.281091</td>\n",
       "      <td>0.178685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_13</th>\n",
       "      <td>0.310937</td>\n",
       "      <td>0.372229</td>\n",
       "      <td>0.446999</td>\n",
       "      <td>0.467446</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.29794</td>\n",
       "      <td>0.56466</td>\n",
       "      <td>0.473146</td>\n",
       "      <td>0.355931</td>\n",
       "      <td>0.556294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235907</td>\n",
       "      <td>0.174456</td>\n",
       "      <td>0.175835</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.215353</td>\n",
       "      <td>0.263101</td>\n",
       "      <td>0.164276</td>\n",
       "      <td>0.283752</td>\n",
       "      <td>0.242272</td>\n",
       "      <td>0.219034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_14</th>\n",
       "      <td>0.304017</td>\n",
       "      <td>0.325704</td>\n",
       "      <td>0.416655</td>\n",
       "      <td>0.38903</td>\n",
       "      <td>0.343176</td>\n",
       "      <td>0.38321</td>\n",
       "      <td>0.516541</td>\n",
       "      <td>0.410045</td>\n",
       "      <td>0.348009</td>\n",
       "      <td>0.508888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187409</td>\n",
       "      <td>0.184787</td>\n",
       "      <td>0.139686</td>\n",
       "      <td>0.161186</td>\n",
       "      <td>0.25662</td>\n",
       "      <td>0.202678</td>\n",
       "      <td>0.116003</td>\n",
       "      <td>0.180334</td>\n",
       "      <td>0.17108</td>\n",
       "      <td>0.290007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_15</th>\n",
       "      <td>0.523148</td>\n",
       "      <td>0.367594</td>\n",
       "      <td>0.300828</td>\n",
       "      <td>0.33706</td>\n",
       "      <td>0.461245</td>\n",
       "      <td>0.626601</td>\n",
       "      <td>0.345467</td>\n",
       "      <td>0.452308</td>\n",
       "      <td>0.506719</td>\n",
       "      <td>0.382892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223263</td>\n",
       "      <td>0.272554</td>\n",
       "      <td>0.24037</td>\n",
       "      <td>0.274319</td>\n",
       "      <td>0.271746</td>\n",
       "      <td>0.261574</td>\n",
       "      <td>0.230327</td>\n",
       "      <td>0.214834</td>\n",
       "      <td>0.294392</td>\n",
       "      <td>0.184261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_16</th>\n",
       "      <td>0.490304</td>\n",
       "      <td>0.331756</td>\n",
       "      <td>0.267845</td>\n",
       "      <td>0.315899</td>\n",
       "      <td>0.412638</td>\n",
       "      <td>0.637598</td>\n",
       "      <td>0.303542</td>\n",
       "      <td>0.406955</td>\n",
       "      <td>0.45332</td>\n",
       "      <td>0.358854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185996</td>\n",
       "      <td>0.235793</td>\n",
       "      <td>0.242608</td>\n",
       "      <td>0.222817</td>\n",
       "      <td>0.212238</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>0.151107</td>\n",
       "      <td>0.178975</td>\n",
       "      <td>0.27591</td>\n",
       "      <td>0.19428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_17</th>\n",
       "      <td>0.404929</td>\n",
       "      <td>0.48709</td>\n",
       "      <td>0.353153</td>\n",
       "      <td>0.502459</td>\n",
       "      <td>0.492248</td>\n",
       "      <td>0.380304</td>\n",
       "      <td>0.386244</td>\n",
       "      <td>0.525924</td>\n",
       "      <td>0.437772</td>\n",
       "      <td>0.546999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249615</td>\n",
       "      <td>0.328165</td>\n",
       "      <td>0.310087</td>\n",
       "      <td>0.306698</td>\n",
       "      <td>0.253185</td>\n",
       "      <td>0.314945</td>\n",
       "      <td>0.257513</td>\n",
       "      <td>0.240192</td>\n",
       "      <td>0.32914</td>\n",
       "      <td>0.180259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_18</th>\n",
       "      <td>0.538639</td>\n",
       "      <td>0.312395</td>\n",
       "      <td>0.306786</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.454344</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.330289</td>\n",
       "      <td>0.461266</td>\n",
       "      <td>0.499137</td>\n",
       "      <td>0.379628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0948683</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.0932505</td>\n",
       "      <td>0.11547</td>\n",
       "      <td>0.153897</td>\n",
       "      <td>0.088083</td>\n",
       "      <td>0.121716</td>\n",
       "      <td>0.173205</td>\n",
       "      <td>0.117444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_19</th>\n",
       "      <td>0.337911</td>\n",
       "      <td>0.442993</td>\n",
       "      <td>0.489419</td>\n",
       "      <td>0.501194</td>\n",
       "      <td>0.418113</td>\n",
       "      <td>0.31945</td>\n",
       "      <td>0.543912</td>\n",
       "      <td>0.49374</td>\n",
       "      <td>0.314281</td>\n",
       "      <td>0.535853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23434</td>\n",
       "      <td>0.242065</td>\n",
       "      <td>0.232889</td>\n",
       "      <td>0.191953</td>\n",
       "      <td>0.190153</td>\n",
       "      <td>0.253433</td>\n",
       "      <td>0.193404</td>\n",
       "      <td>0.225494</td>\n",
       "      <td>0.26146</td>\n",
       "      <td>0.241755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_20</th>\n",
       "      <td>0.551825</td>\n",
       "      <td>0.394126</td>\n",
       "      <td>0.343762</td>\n",
       "      <td>0.406562</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>0.600099</td>\n",
       "      <td>0.460566</td>\n",
       "      <td>0.496186</td>\n",
       "      <td>0.56149</td>\n",
       "      <td>0.518563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.195047</td>\n",
       "      <td>0.20702</td>\n",
       "      <td>0.214599</td>\n",
       "      <td>0.175466</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.241523</td>\n",
       "      <td>0.210559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_22</th>\n",
       "      <td>0.439797</td>\n",
       "      <td>0.368433</td>\n",
       "      <td>0.25049</td>\n",
       "      <td>0.350823</td>\n",
       "      <td>0.37097</td>\n",
       "      <td>0.633553</td>\n",
       "      <td>0.3371</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>0.45549</td>\n",
       "      <td>0.376386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206559</td>\n",
       "      <td>0.24004</td>\n",
       "      <td>0.23094</td>\n",
       "      <td>0.209381</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.251312</td>\n",
       "      <td>0.191785</td>\n",
       "      <td>0.173916</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.167812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_23</th>\n",
       "      <td>0.564782</td>\n",
       "      <td>0.38215</td>\n",
       "      <td>0.37998</td>\n",
       "      <td>0.47305</td>\n",
       "      <td>0.559065</td>\n",
       "      <td>0.502519</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.533229</td>\n",
       "      <td>0.614183</td>\n",
       "      <td>0.537373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243709</td>\n",
       "      <td>0.294245</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.307996</td>\n",
       "      <td>0.286039</td>\n",
       "      <td>0.338869</td>\n",
       "      <td>0.258603</td>\n",
       "      <td>0.335013</td>\n",
       "      <td>0.381385</td>\n",
       "      <td>0.290929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_24</th>\n",
       "      <td>0.350438</td>\n",
       "      <td>0.355677</td>\n",
       "      <td>0.486513</td>\n",
       "      <td>0.471728</td>\n",
       "      <td>0.469476</td>\n",
       "      <td>0.356348</td>\n",
       "      <td>0.510355</td>\n",
       "      <td>0.585194</td>\n",
       "      <td>0.401148</td>\n",
       "      <td>0.529256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>0.182574</td>\n",
       "      <td>0.115011</td>\n",
       "      <td>0.0910032</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.175219</td>\n",
       "      <td>0.143267</td>\n",
       "      <td>0.20787</td>\n",
       "      <td>0.197203</td>\n",
       "      <td>0.200574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_25</th>\n",
       "      <td>0.346339</td>\n",
       "      <td>0.351517</td>\n",
       "      <td>0.480822</td>\n",
       "      <td>0.466211</td>\n",
       "      <td>0.463985</td>\n",
       "      <td>0.35218</td>\n",
       "      <td>0.504385</td>\n",
       "      <td>0.578349</td>\n",
       "      <td>0.396456</td>\n",
       "      <td>0.523066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152499</td>\n",
       "      <td>0.180439</td>\n",
       "      <td>0.113666</td>\n",
       "      <td>0.0899388</td>\n",
       "      <td>0.167054</td>\n",
       "      <td>0.17317</td>\n",
       "      <td>0.141591</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>0.194896</td>\n",
       "      <td>0.198228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_26</th>\n",
       "      <td>0.545173</td>\n",
       "      <td>0.353512</td>\n",
       "      <td>0.271694</td>\n",
       "      <td>0.332956</td>\n",
       "      <td>0.449712</td>\n",
       "      <td>0.666973</td>\n",
       "      <td>0.316885</td>\n",
       "      <td>0.408504</td>\n",
       "      <td>0.520051</td>\n",
       "      <td>0.336204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196039</td>\n",
       "      <td>0.284029</td>\n",
       "      <td>0.229616</td>\n",
       "      <td>0.289044</td>\n",
       "      <td>0.255655</td>\n",
       "      <td>0.227155</td>\n",
       "      <td>0.156015</td>\n",
       "      <td>0.188639</td>\n",
       "      <td>0.255655</td>\n",
       "      <td>0.182018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_1</th>\n",
       "      <td>0.127257</td>\n",
       "      <td>0.0861062</td>\n",
       "      <td>0.261608</td>\n",
       "      <td>0.222058</td>\n",
       "      <td>0.165748</td>\n",
       "      <td>0.113228</td>\n",
       "      <td>0.170697</td>\n",
       "      <td>0.143032</td>\n",
       "      <td>0.109254</td>\n",
       "      <td>0.0672673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509902</td>\n",
       "      <td>0.430946</td>\n",
       "      <td>0.467764</td>\n",
       "      <td>0.520483</td>\n",
       "      <td>0.393863</td>\n",
       "      <td>0.445399</td>\n",
       "      <td>0.50985</td>\n",
       "      <td>0.415168</td>\n",
       "      <td>0.429669</td>\n",
       "      <td>0.437014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_2</th>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.171968</td>\n",
       "      <td>0.18999</td>\n",
       "      <td>0.157683</td>\n",
       "      <td>0.205971</td>\n",
       "      <td>0.201008</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.152351</td>\n",
       "      <td>0.161627</td>\n",
       "      <td>0.14927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417786</td>\n",
       "      <td>0.470792</td>\n",
       "      <td>0.518999</td>\n",
       "      <td>0.538993</td>\n",
       "      <td>0.476731</td>\n",
       "      <td>0.508304</td>\n",
       "      <td>0.42023</td>\n",
       "      <td>0.435516</td>\n",
       "      <td>0.508513</td>\n",
       "      <td>0.484881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_3</th>\n",
       "      <td>0.166924</td>\n",
       "      <td>0.207069</td>\n",
       "      <td>0.311959</td>\n",
       "      <td>0.233021</td>\n",
       "      <td>0.20292</td>\n",
       "      <td>0.173276</td>\n",
       "      <td>0.238833</td>\n",
       "      <td>0.225141</td>\n",
       "      <td>0.191079</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445896</td>\n",
       "      <td>0.550782</td>\n",
       "      <td>0.536875</td>\n",
       "      <td>0.657438</td>\n",
       "      <td>0.469668</td>\n",
       "      <td>0.445132</td>\n",
       "      <td>0.477697</td>\n",
       "      <td>0.462069</td>\n",
       "      <td>0.438357</td>\n",
       "      <td>0.382158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_4</th>\n",
       "      <td>0.218537</td>\n",
       "      <td>0.168993</td>\n",
       "      <td>0.186704</td>\n",
       "      <td>0.174325</td>\n",
       "      <td>0.16265</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.234509</td>\n",
       "      <td>0.16843</td>\n",
       "      <td>0.142948</td>\n",
       "      <td>0.13202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46188</td>\n",
       "      <td>0.48795</td>\n",
       "      <td>0.545087</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.49191</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.428845</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>0.428845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_5</th>\n",
       "      <td>0.155857</td>\n",
       "      <td>0.123034</td>\n",
       "      <td>0.213602</td>\n",
       "      <td>0.253833</td>\n",
       "      <td>0.243599</td>\n",
       "      <td>0.138675</td>\n",
       "      <td>0.167248</td>\n",
       "      <td>0.233571</td>\n",
       "      <td>0.208145</td>\n",
       "      <td>0.137309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480384</td>\n",
       "      <td>0.487199</td>\n",
       "      <td>0.525151</td>\n",
       "      <td>0.448583</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.519524</td>\n",
       "      <td>0.446026</td>\n",
       "      <td>0.431433</td>\n",
       "      <td>0.467764</td>\n",
       "      <td>0.475761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_6</th>\n",
       "      <td>0.127257</td>\n",
       "      <td>0.107633</td>\n",
       "      <td>0.214043</td>\n",
       "      <td>0.133235</td>\n",
       "      <td>0.232048</td>\n",
       "      <td>0.113228</td>\n",
       "      <td>0.170697</td>\n",
       "      <td>0.200245</td>\n",
       "      <td>0.182089</td>\n",
       "      <td>0.201802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509902</td>\n",
       "      <td>0.364646</td>\n",
       "      <td>0.292353</td>\n",
       "      <td>0.346989</td>\n",
       "      <td>0.429669</td>\n",
       "      <td>0.477214</td>\n",
       "      <td>0.473432</td>\n",
       "      <td>0.415168</td>\n",
       "      <td>0.358057</td>\n",
       "      <td>0.50985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_7</th>\n",
       "      <td>0.201211</td>\n",
       "      <td>0.204219</td>\n",
       "      <td>0.255704</td>\n",
       "      <td>0.308972</td>\n",
       "      <td>0.209657</td>\n",
       "      <td>0.179029</td>\n",
       "      <td>0.194325</td>\n",
       "      <td>0.253293</td>\n",
       "      <td>0.230327</td>\n",
       "      <td>0.148902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372104</td>\n",
       "      <td>0.628971</td>\n",
       "      <td>0.66564</td>\n",
       "      <td>0.621789</td>\n",
       "      <td>0.384974</td>\n",
       "      <td>0.503027</td>\n",
       "      <td>0.529751</td>\n",
       "      <td>0.47741</td>\n",
       "      <td>0.543493</td>\n",
       "      <td>0.368523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_8</th>\n",
       "      <td>0.190885</td>\n",
       "      <td>0.172212</td>\n",
       "      <td>0.285391</td>\n",
       "      <td>0.266469</td>\n",
       "      <td>0.198898</td>\n",
       "      <td>0.226455</td>\n",
       "      <td>0.238976</td>\n",
       "      <td>0.257458</td>\n",
       "      <td>0.254925</td>\n",
       "      <td>0.201802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549125</td>\n",
       "      <td>0.662994</td>\n",
       "      <td>0.55547</td>\n",
       "      <td>0.578315</td>\n",
       "      <td>0.50128</td>\n",
       "      <td>0.477214</td>\n",
       "      <td>0.619103</td>\n",
       "      <td>0.490653</td>\n",
       "      <td>0.465475</td>\n",
       "      <td>0.473432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_9</th>\n",
       "      <td>0.179969</td>\n",
       "      <td>0.167437</td>\n",
       "      <td>0.235435</td>\n",
       "      <td>0.266932</td>\n",
       "      <td>0.164083</td>\n",
       "      <td>0.160128</td>\n",
       "      <td>0.193122</td>\n",
       "      <td>0.202278</td>\n",
       "      <td>0.231762</td>\n",
       "      <td>0.190261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471495</td>\n",
       "      <td>0.63289</td>\n",
       "      <td>0.661519</td>\n",
       "      <td>0.674735</td>\n",
       "      <td>0.481051</td>\n",
       "      <td>0.517409</td>\n",
       "      <td>0.540778</td>\n",
       "      <td>0.533761</td>\n",
       "      <td>0.531688</td>\n",
       "      <td>0.38627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_10</th>\n",
       "      <td>0.157472</td>\n",
       "      <td>0.228323</td>\n",
       "      <td>0.235435</td>\n",
       "      <td>0.282633</td>\n",
       "      <td>0.140642</td>\n",
       "      <td>0.220176</td>\n",
       "      <td>0.193122</td>\n",
       "      <td>0.262962</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.166478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44376</td>\n",
       "      <td>0.609449</td>\n",
       "      <td>0.640846</td>\n",
       "      <td>0.552056</td>\n",
       "      <td>0.481051</td>\n",
       "      <td>0.517409</td>\n",
       "      <td>0.515026</td>\n",
       "      <td>0.533761</td>\n",
       "      <td>0.557007</td>\n",
       "      <td>0.360518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_11</th>\n",
       "      <td>0.171191</td>\n",
       "      <td>0.182023</td>\n",
       "      <td>0.292509</td>\n",
       "      <td>0.221906</td>\n",
       "      <td>0.178377</td>\n",
       "      <td>0.195837</td>\n",
       "      <td>0.157459</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.195962</td>\n",
       "      <td>0.206835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633174</td>\n",
       "      <td>0.586094</td>\n",
       "      <td>0.516887</td>\n",
       "      <td>0.555693</td>\n",
       "      <td>0.688102</td>\n",
       "      <td>0.562483</td>\n",
       "      <td>0.503903</td>\n",
       "      <td>0.551246</td>\n",
       "      <td>0.522958</td>\n",
       "      <td>0.559893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_12</th>\n",
       "      <td>0.162221</td>\n",
       "      <td>0.164646</td>\n",
       "      <td>0.323381</td>\n",
       "      <td>0.245327</td>\n",
       "      <td>0.225374</td>\n",
       "      <td>0.216506</td>\n",
       "      <td>0.232104</td>\n",
       "      <td>0.218797</td>\n",
       "      <td>0.247594</td>\n",
       "      <td>0.200082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.591608</td>\n",
       "      <td>0.57144</td>\n",
       "      <td>0.663489</td>\n",
       "      <td>0.608581</td>\n",
       "      <td>0.513701</td>\n",
       "      <td>0.618984</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.486864</td>\n",
       "      <td>0.464238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_13</th>\n",
       "      <td>0.170406</td>\n",
       "      <td>0.201779</td>\n",
       "      <td>0.238849</td>\n",
       "      <td>0.23788</td>\n",
       "      <td>0.155364</td>\n",
       "      <td>0.208477</td>\n",
       "      <td>0.160003</td>\n",
       "      <td>0.248989</td>\n",
       "      <td>0.195064</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446442</td>\n",
       "      <td>0.532676</td>\n",
       "      <td>0.606794</td>\n",
       "      <td>0.735683</td>\n",
       "      <td>0.52741</td>\n",
       "      <td>0.468616</td>\n",
       "      <td>0.536426</td>\n",
       "      <td>0.505399</td>\n",
       "      <td>0.431517</td>\n",
       "      <td>0.414511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_14</th>\n",
       "      <td>0.146735</td>\n",
       "      <td>0.165476</td>\n",
       "      <td>0.237664</td>\n",
       "      <td>0.273115</td>\n",
       "      <td>0.152894</td>\n",
       "      <td>0.217597</td>\n",
       "      <td>0.183702</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.139973</td>\n",
       "      <td>0.129272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54272</td>\n",
       "      <td>0.509647</td>\n",
       "      <td>0.651727</td>\n",
       "      <td>0.511237</td>\n",
       "      <td>0.550482</td>\n",
       "      <td>0.46466</td>\n",
       "      <td>0.531898</td>\n",
       "      <td>0.435194</td>\n",
       "      <td>0.578006</td>\n",
       "      <td>0.447914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_15</th>\n",
       "      <td>0.123693</td>\n",
       "      <td>0.15065</td>\n",
       "      <td>0.240411</td>\n",
       "      <td>0.328074</td>\n",
       "      <td>0.154662</td>\n",
       "      <td>0.132068</td>\n",
       "      <td>0.185826</td>\n",
       "      <td>0.222442</td>\n",
       "      <td>0.198228</td>\n",
       "      <td>0.15692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518495</td>\n",
       "      <td>0.618647</td>\n",
       "      <td>0.636528</td>\n",
       "      <td>0.607087</td>\n",
       "      <td>0.473319</td>\n",
       "      <td>0.445294</td>\n",
       "      <td>0.566365</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.501161</td>\n",
       "      <td>0.396456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_16</th>\n",
       "      <td>0.162221</td>\n",
       "      <td>0.131717</td>\n",
       "      <td>0.266789</td>\n",
       "      <td>0.226455</td>\n",
       "      <td>0.135225</td>\n",
       "      <td>0.173205</td>\n",
       "      <td>0.243709</td>\n",
       "      <td>0.233384</td>\n",
       "      <td>0.185695</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.473286</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.501303</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.583997</td>\n",
       "      <td>0.557086</td>\n",
       "      <td>0.53886</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.594225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_17</th>\n",
       "      <td>0.191943</td>\n",
       "      <td>0.185535</td>\n",
       "      <td>0.20498</td>\n",
       "      <td>0.248807</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.219578</td>\n",
       "      <td>0.205971</td>\n",
       "      <td>0.221901</td>\n",
       "      <td>0.219718</td>\n",
       "      <td>0.20292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>0.598134</td>\n",
       "      <td>0.524631</td>\n",
       "      <td>0.520988</td>\n",
       "      <td>0.596377</td>\n",
       "      <td>0.55301</td>\n",
       "      <td>0.524631</td>\n",
       "      <td>0.439435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_18</th>\n",
       "      <td>0.169278</td>\n",
       "      <td>0.147264</td>\n",
       "      <td>0.235008</td>\n",
       "      <td>0.270064</td>\n",
       "      <td>0.151186</td>\n",
       "      <td>0.150616</td>\n",
       "      <td>0.2076</td>\n",
       "      <td>0.260931</td>\n",
       "      <td>0.166091</td>\n",
       "      <td>0.178958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>0</td>\n",
       "      <td>0.549484</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.532016</td>\n",
       "      <td>0.553637</td>\n",
       "      <td>0.430331</td>\n",
       "      <td>0.598764</td>\n",
       "      <td>0.3045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_19</th>\n",
       "      <td>0.191346</td>\n",
       "      <td>0.194206</td>\n",
       "      <td>0.250319</td>\n",
       "      <td>0.233723</td>\n",
       "      <td>0.174456</td>\n",
       "      <td>0.212814</td>\n",
       "      <td>0.205331</td>\n",
       "      <td>0.19356</td>\n",
       "      <td>0.246414</td>\n",
       "      <td>0.177003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501303</td>\n",
       "      <td>0.598134</td>\n",
       "      <td>0.549484</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565301</td>\n",
       "      <td>0.574038</td>\n",
       "      <td>0.520206</td>\n",
       "      <td>0.539129</td>\n",
       "      <td>0.457625</td>\n",
       "      <td>0.410689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_20</th>\n",
       "      <td>0.177705</td>\n",
       "      <td>0.180361</td>\n",
       "      <td>0.265684</td>\n",
       "      <td>0.206725</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>0.237171</td>\n",
       "      <td>0.222475</td>\n",
       "      <td>0.266312</td>\n",
       "      <td>0.203419</td>\n",
       "      <td>0.219179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.524631</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.565301</td>\n",
       "      <td>0</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>0.576354</td>\n",
       "      <td>0.562183</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.610257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_21</th>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.249286</td>\n",
       "      <td>0.334428</td>\n",
       "      <td>0.257151</td>\n",
       "      <td>0.246784</td>\n",
       "      <td>0.210732</td>\n",
       "      <td>0.254152</td>\n",
       "      <td>0.283949</td>\n",
       "      <td>0.210866</td>\n",
       "      <td>0.222566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583997</td>\n",
       "      <td>0.520988</td>\n",
       "      <td>0.532016</td>\n",
       "      <td>0.574038</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>0</td>\n",
       "      <td>0.572351</td>\n",
       "      <td>0.561951</td>\n",
       "      <td>0.710819</td>\n",
       "      <td>0.572351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_22</th>\n",
       "      <td>0.150619</td>\n",
       "      <td>0.142679</td>\n",
       "      <td>0.247708</td>\n",
       "      <td>0.25231</td>\n",
       "      <td>0.188329</td>\n",
       "      <td>0.160817</td>\n",
       "      <td>0.258603</td>\n",
       "      <td>0.297951</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.191079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557086</td>\n",
       "      <td>0.596377</td>\n",
       "      <td>0.553637</td>\n",
       "      <td>0.520206</td>\n",
       "      <td>0.576354</td>\n",
       "      <td>0.572351</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571793</td>\n",
       "      <td>0.576354</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_23</th>\n",
       "      <td>0.187317</td>\n",
       "      <td>0.211241</td>\n",
       "      <td>0.23338</td>\n",
       "      <td>0.261488</td>\n",
       "      <td>0.22771</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.280717</td>\n",
       "      <td>0.214423</td>\n",
       "      <td>0.264039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53886</td>\n",
       "      <td>0.55301</td>\n",
       "      <td>0.430331</td>\n",
       "      <td>0.539129</td>\n",
       "      <td>0.562183</td>\n",
       "      <td>0.561951</td>\n",
       "      <td>0.571793</td>\n",
       "      <td>0</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.536056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_24</th>\n",
       "      <td>0.266557</td>\n",
       "      <td>0.240481</td>\n",
       "      <td>0.309965</td>\n",
       "      <td>0.268742</td>\n",
       "      <td>0.277746</td>\n",
       "      <td>0.210819</td>\n",
       "      <td>0.286039</td>\n",
       "      <td>0.319574</td>\n",
       "      <td>0.203419</td>\n",
       "      <td>0.219179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.524631</td>\n",
       "      <td>0.598764</td>\n",
       "      <td>0.457625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.710819</td>\n",
       "      <td>0.576354</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_25</th>\n",
       "      <td>0.210866</td>\n",
       "      <td>0.183444</td>\n",
       "      <td>0.270226</td>\n",
       "      <td>0.189233</td>\n",
       "      <td>0.219718</td>\n",
       "      <td>0.160817</td>\n",
       "      <td>0.193952</td>\n",
       "      <td>0.189605</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.159232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594225</td>\n",
       "      <td>0.439435</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>0.410689</td>\n",
       "      <td>0.610257</td>\n",
       "      <td>0.572351</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.536056</td>\n",
       "      <td>0.542451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           d_1        d_2       d_3       d_4       d_5       d_6       d_7  \\\n",
       "d_1          0    0.32051  0.373773  0.348991  0.575829  0.608781  0.367109   \n",
       "d_2    0.32051          0   0.45257  0.484706  0.352517  0.316862   0.30572   \n",
       "d_3   0.373773    0.45257         0  0.494312  0.430458  0.280056   0.52775   \n",
       "d_4   0.348991   0.484706  0.494312         0  0.401918  0.294174   0.45334   \n",
       "d_5   0.575829   0.352517  0.430458  0.401918         0   0.48795  0.500216   \n",
       "d_6   0.608781   0.316862  0.280056  0.294174   0.48795         0  0.351763   \n",
       "d_7   0.367109    0.30572   0.52775   0.45334  0.500216  0.351763         0   \n",
       "d_8   0.473249   0.432291  0.495284  0.495479  0.517769  0.463184  0.533229   \n",
       "d_9   0.602475   0.305741   0.40534  0.420517  0.596377  0.562859   0.42023   \n",
       "d_10   0.38949    0.47061  0.499134  0.466041  0.492805  0.420813  0.597081   \n",
       "d_11  0.390007   0.341506  0.497346   0.51241  0.430282  0.387836  0.541603   \n",
       "d_12  0.530732   0.401359  0.443422  0.414023   0.61807  0.555556  0.502519   \n",
       "d_13  0.310937   0.372229  0.446999  0.467446    0.4486   0.29794   0.56466   \n",
       "d_14  0.304017   0.325704  0.416655   0.38903  0.343176   0.38321  0.516541   \n",
       "d_15  0.523148   0.367594  0.300828   0.33706  0.461245  0.626601  0.345467   \n",
       "d_16  0.490304   0.331756  0.267845  0.315899  0.412638  0.637598  0.303542   \n",
       "d_17  0.404929    0.48709  0.353153  0.502459  0.492248  0.380304  0.386244   \n",
       "d_18  0.538639   0.312395  0.306786  0.268543  0.454344  0.730297  0.330289   \n",
       "d_19  0.337911   0.442993  0.489419  0.501194  0.418113   0.31945  0.543912   \n",
       "d_20  0.551825   0.394126  0.343762  0.406562  0.543045  0.600099  0.460566   \n",
       "d_22  0.439797   0.368433   0.25049  0.350823   0.37097  0.633553    0.3371   \n",
       "d_23  0.564782    0.38215   0.37998   0.47305  0.559065  0.502519  0.545455   \n",
       "d_24  0.350438   0.355677  0.486513  0.471728  0.469476  0.356348  0.510355   \n",
       "d_25  0.346339   0.351517  0.480822  0.466211  0.463985   0.35218  0.504385   \n",
       "d_26  0.545173   0.353512  0.271694  0.332956  0.449712  0.666973  0.316885   \n",
       "c_1   0.127257  0.0861062  0.261608  0.222058  0.165748  0.113228  0.170697   \n",
       "c_2   0.197674   0.171968   0.18999  0.157683  0.205971  0.201008  0.181818   \n",
       "c_3   0.166924   0.207069  0.311959  0.233021   0.20292  0.173276  0.238833   \n",
       "c_4   0.218537   0.168993  0.186704  0.174325   0.16265  0.222222  0.234509   \n",
       "c_5   0.155857   0.123034  0.213602  0.253833  0.243599  0.138675  0.167248   \n",
       "c_6   0.127257   0.107633  0.214043  0.133235  0.232048  0.113228  0.170697   \n",
       "c_7   0.201211   0.204219  0.255704  0.308972  0.209657  0.179029  0.194325   \n",
       "c_8   0.190885   0.172212  0.285391  0.266469  0.198898  0.226455  0.238976   \n",
       "c_9   0.179969   0.167437  0.235435  0.266932  0.164083  0.160128  0.193122   \n",
       "c_10  0.157472   0.228323  0.235435  0.282633  0.140642  0.220176  0.193122   \n",
       "c_11  0.171191   0.182023  0.292509  0.221906  0.178377  0.195837  0.157459   \n",
       "c_12  0.162221   0.164646  0.323381  0.245327  0.225374  0.216506  0.232104   \n",
       "c_13  0.170406   0.201779  0.238849   0.23788  0.155364  0.208477  0.160003   \n",
       "c_14  0.146735   0.165476  0.237664  0.273115  0.152894  0.217597  0.183702   \n",
       "c_15  0.123693    0.15065  0.240411  0.328074  0.154662  0.132068  0.185826   \n",
       "c_16  0.162221   0.131717  0.266789  0.226455  0.135225  0.173205  0.243709   \n",
       "c_17  0.191943   0.185535   0.20498  0.248807  0.171429  0.219578  0.205971   \n",
       "c_18  0.169278   0.147264  0.235008  0.270064  0.151186  0.150616    0.2076   \n",
       "c_19  0.191346   0.194206  0.250319  0.233723  0.174456  0.212814  0.205331   \n",
       "c_20  0.177705   0.180361  0.265684  0.206725  0.154303  0.237171  0.222475   \n",
       "c_21  0.236842   0.249286  0.334428  0.257151  0.246784  0.210732  0.254152   \n",
       "c_22  0.150619   0.142679  0.247708   0.25231  0.188329  0.160817  0.258603   \n",
       "c_23  0.187317   0.211241   0.23338  0.261488   0.22771  0.166667  0.301511   \n",
       "c_24  0.266557   0.240481  0.309965  0.268742  0.277746  0.210819  0.286039   \n",
       "c_25  0.210866   0.183444  0.270226  0.189233  0.219718  0.160817  0.193952   \n",
       "\n",
       "           d_8       d_9       d_10  ...       c_16      c_17      c_18  \\\n",
       "d_1   0.473249  0.602475    0.38949  ...   0.162221  0.191943  0.169278   \n",
       "d_2   0.432291  0.305741    0.47061  ...   0.131717  0.185535  0.147264   \n",
       "d_3   0.495284   0.40534   0.499134  ...   0.266789   0.20498  0.235008   \n",
       "d_4   0.495479  0.420517   0.466041  ...   0.226455  0.248807  0.270064   \n",
       "d_5   0.517769  0.596377   0.492805  ...   0.135225  0.171429  0.151186   \n",
       "d_6   0.463184  0.562859   0.420813  ...   0.173205  0.219578  0.150616   \n",
       "d_7   0.533229   0.42023   0.597081  ...   0.243709  0.205971    0.2076   \n",
       "d_8          0  0.568815   0.600375  ...   0.233384  0.221901  0.260931   \n",
       "d_9   0.568815         0    0.54139  ...   0.185695  0.219718  0.166091   \n",
       "d_10  0.600375   0.54139          0  ...   0.171499   0.20292  0.178958   \n",
       "d_11  0.515711  0.446442   0.582086  ...    0.19799  0.215141  0.189737   \n",
       "d_12  0.533363  0.643268   0.627093  ...    0.15396   0.22771  0.200821   \n",
       "d_13  0.473146  0.355931   0.556294  ...   0.235907  0.174456  0.175835   \n",
       "d_14  0.410045  0.348009   0.508888  ...   0.187409  0.184787  0.139686   \n",
       "d_15  0.452308  0.506719   0.382892  ...   0.223263  0.272554   0.24037   \n",
       "d_16  0.406955   0.45332   0.358854  ...   0.185996  0.235793  0.242608   \n",
       "d_17  0.525924  0.437772   0.546999  ...   0.249615  0.328165  0.310087   \n",
       "d_18  0.461266  0.499137   0.379628  ...  0.0948683  0.133631  0.117851   \n",
       "d_19   0.49374  0.314281   0.535853  ...    0.23434  0.242065  0.232889   \n",
       "d_20  0.496186   0.56149   0.518563  ...   0.188982  0.223607  0.169031   \n",
       "d_22  0.451946   0.45549   0.376386  ...   0.206559   0.24004   0.23094   \n",
       "d_23  0.533229  0.614183   0.537373  ...   0.243709  0.294245    0.2595   \n",
       "d_24  0.585194  0.401148   0.529256  ...   0.154303  0.182574  0.115011   \n",
       "d_25  0.578349  0.396456   0.523066  ...   0.152499  0.180439  0.113666   \n",
       "d_26  0.408504  0.520051   0.336204  ...   0.196039  0.284029  0.229616   \n",
       "c_1   0.143032  0.109254  0.0672673  ...   0.509902  0.430946  0.467764   \n",
       "c_2   0.152351  0.161627    0.14927  ...   0.417786  0.470792  0.518999   \n",
       "c_3   0.225141  0.191079   0.176471  ...   0.445896  0.550782  0.536875   \n",
       "c_4    0.16843  0.142948    0.13202  ...    0.46188   0.48795  0.545087   \n",
       "c_5   0.233571  0.208145   0.137309  ...   0.480384  0.487199  0.525151   \n",
       "c_6   0.200245  0.182089   0.201802  ...   0.509902  0.364646  0.292353   \n",
       "c_7   0.253293  0.230327   0.148902  ...   0.372104  0.628971   0.66564   \n",
       "c_8   0.257458  0.254925   0.201802  ...   0.549125  0.662994   0.55547   \n",
       "c_9   0.202278  0.231762   0.190261  ...   0.471495   0.63289  0.661519   \n",
       "c_10  0.262962  0.180259   0.166478  ...    0.44376  0.609449  0.640846   \n",
       "c_11    0.2199  0.195962   0.206835  ...   0.633174  0.586094  0.516887   \n",
       "c_12  0.218797  0.247594   0.200082  ...   0.533333  0.591608   0.57144   \n",
       "c_13  0.248989  0.195064   0.135113  ...   0.446442  0.532676  0.606794   \n",
       "c_14    0.2199  0.139973   0.129272  ...    0.54272  0.509647  0.651727   \n",
       "c_15  0.222442  0.198228    0.15692  ...   0.518495  0.618647  0.636528   \n",
       "c_16  0.233384  0.185695   0.171499  ...          0  0.473286  0.447214   \n",
       "c_17  0.221901  0.219718    0.20292  ...   0.473286         0  0.604743   \n",
       "c_18  0.260931  0.166091   0.178958  ...   0.447214  0.604743         0   \n",
       "c_19   0.19356  0.246414   0.177003  ...   0.501303  0.598134  0.549484   \n",
       "c_20  0.266312  0.203419   0.219179  ...   0.730297  0.524631  0.408248   \n",
       "c_21  0.283949  0.210866   0.222566  ...   0.583997  0.520988  0.532016   \n",
       "c_22  0.297951  0.206897   0.191079  ...   0.557086  0.596377  0.553637   \n",
       "c_23  0.280717  0.214423   0.264039  ...    0.53886   0.55301  0.430331   \n",
       "c_24  0.319574  0.203419   0.219179  ...   0.511208  0.524631  0.598764   \n",
       "c_25  0.189605  0.172414   0.159232  ...   0.594225  0.439435    0.3045   \n",
       "\n",
       "           c_19      c_20      c_21      c_22      c_23      c_24      c_25  \n",
       "d_1    0.191346  0.177705  0.236842  0.150619  0.187317  0.266557  0.210866  \n",
       "d_2    0.194206  0.180361  0.249286  0.142679  0.211241  0.240481  0.183444  \n",
       "d_3    0.250319  0.265684  0.334428  0.247708   0.23338  0.309965  0.270226  \n",
       "d_4    0.233723  0.206725  0.257151   0.25231  0.261488  0.268742  0.189233  \n",
       "d_5    0.174456  0.154303  0.246784  0.188329   0.22771  0.277746  0.219718  \n",
       "d_6    0.212814  0.237171  0.210732  0.160817  0.166667  0.210819  0.160817  \n",
       "d_7    0.205331  0.222475  0.254152  0.258603  0.301511  0.286039  0.193952  \n",
       "d_8     0.19356  0.266312  0.283949  0.297951  0.280717  0.319574  0.189605  \n",
       "d_9    0.246414  0.203419  0.210866  0.206897  0.214423  0.203419  0.172414  \n",
       "d_10   0.177003  0.219179  0.222566  0.191079  0.264039  0.219179  0.159232  \n",
       "d_11   0.229366  0.232379  0.183533   0.21009  0.190516  0.180739  0.183829  \n",
       "d_12   0.170251  0.175682  0.218537  0.214423  0.259259  0.281091  0.178685  \n",
       "d_13   0.217391  0.215353  0.263101  0.164276  0.283752  0.242272  0.219034  \n",
       "d_14   0.161186   0.25662  0.202678  0.116003  0.180334   0.17108  0.290007  \n",
       "d_15   0.274319  0.271746  0.261574  0.230327  0.214834  0.294392  0.184261  \n",
       "d_16   0.222817  0.212238  0.226294  0.151107  0.178975   0.27591   0.19428  \n",
       "d_17   0.306698  0.253185  0.314945  0.257513  0.240192   0.32914  0.180259  \n",
       "d_18  0.0932505   0.11547  0.153897  0.088083  0.121716  0.173205  0.117444  \n",
       "d_19   0.191953  0.190153  0.253433  0.193404  0.225494   0.26146  0.241755  \n",
       "d_20   0.195047   0.20702  0.214599  0.175466  0.218218  0.241523  0.210559  \n",
       "d_22   0.209381  0.235702  0.251312  0.191785  0.173916  0.235702  0.167812  \n",
       "d_23   0.307996  0.286039  0.338869  0.258603  0.335013  0.381385  0.290929  \n",
       "d_24  0.0910032  0.169031  0.175219  0.143267   0.20787  0.197203  0.200574  \n",
       "d_25  0.0899388  0.167054   0.17317  0.141591  0.205439  0.194896  0.198228  \n",
       "d_26   0.289044  0.255655  0.227155  0.156015  0.188639  0.255655  0.182018  \n",
       "c_1    0.520483  0.393863  0.445399   0.50985  0.415168  0.429669  0.437014  \n",
       "c_2    0.538993  0.476731  0.508304   0.42023  0.435516  0.508513  0.484881  \n",
       "c_3    0.657438  0.469668  0.445132  0.477697  0.462069  0.438357  0.382158  \n",
       "c_4    0.510754   0.49191  0.499512  0.428845  0.407407  0.527046  0.428845  \n",
       "c_5    0.448583     0.497  0.519524  0.446026  0.431433  0.467764  0.475761  \n",
       "c_6    0.346989  0.429669  0.477214  0.473432  0.415168  0.358057   0.50985  \n",
       "c_7    0.621789  0.384974  0.503027  0.529751   0.47741  0.543493  0.368523  \n",
       "c_8    0.578315   0.50128  0.477214  0.619103  0.490653  0.465475  0.473432  \n",
       "c_9    0.674735  0.481051  0.517409  0.540778  0.533761  0.531688   0.38627  \n",
       "c_10   0.552056  0.481051  0.517409  0.515026  0.533761  0.557007  0.360518  \n",
       "c_11   0.555693  0.688102  0.562483  0.503903  0.551246  0.522958  0.559893  \n",
       "c_12   0.663489  0.608581  0.513701  0.618984   0.57735  0.486864  0.464238  \n",
       "c_13   0.735683   0.52741  0.468616  0.536426  0.505399  0.431517  0.414511  \n",
       "c_14   0.511237  0.550482   0.46466  0.531898  0.435194  0.578006  0.447914  \n",
       "c_15   0.607087  0.473319  0.445294  0.566365  0.586967  0.501161  0.396456  \n",
       "c_16   0.501303  0.730297  0.583997  0.557086   0.53886  0.511208  0.594225  \n",
       "c_17   0.598134  0.524631  0.520988  0.596377   0.55301  0.524631  0.439435  \n",
       "c_18   0.549484  0.408248  0.532016  0.553637  0.430331  0.598764    0.3045  \n",
       "c_19          0  0.565301  0.574038  0.520206  0.539129  0.457625  0.410689  \n",
       "c_20   0.565301         0  0.592349  0.576354  0.562183       0.5  0.610257  \n",
       "c_21   0.574038  0.592349         0  0.572351  0.561951  0.710819  0.572351  \n",
       "c_22   0.520206  0.576354  0.572351         0  0.571793  0.576354  0.482759  \n",
       "c_23   0.539129  0.562183  0.561951  0.571793         0  0.632456  0.536056  \n",
       "c_24   0.457625       0.5  0.710819  0.576354  0.632456         0  0.542451  \n",
       "c_25   0.410689  0.610257  0.572351  0.482759  0.536056  0.542451         0  \n",
       "\n",
       "[50 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fill in each index as cosine similarity value by called the get_cosine() function\n",
    "\n",
    "for i in range(0,len(item_item_matrix.columns)) :\n",
    "    for j in range(0,len(item_item_matrix.columns)) :\n",
    "        if i==j:\n",
    "            item_item_matrix.iloc[i,j] = 0\n",
    "        else:\n",
    "            item_item_matrix.iloc[i,j] = get_cosine(item_matrix.iloc[:,i],item_matrix.iloc[:,j])\n",
    "    \n",
    "item_item_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://medium.com/sfu-cspmp/recommendation-systems-user-based-collaborative-filtering-using-n-nearest-neighbors-bf7361dc24e0\n",
    "# define a function named find_n_neighbours()\n",
    "\n",
    "def find_n_neighbours(df,n):\n",
    "    order = np.argsort(df.values, axis=1)[:, :n]\n",
    "    df = df.apply(lambda x: pd.Series(x.sort_values(ascending=False)\n",
    "           .iloc[:n].index, \n",
    "          index=['top{}'.format(i) for i in range(1, n+1)]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top1</th>\n",
       "      <th>top2</th>\n",
       "      <th>top3</th>\n",
       "      <th>top4</th>\n",
       "      <th>top5</th>\n",
       "      <th>top6</th>\n",
       "      <th>top7</th>\n",
       "      <th>top8</th>\n",
       "      <th>top9</th>\n",
       "      <th>top10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d_1</th>\n",
       "      <td>d_6</td>\n",
       "      <td>d_9</td>\n",
       "      <td>d_5</td>\n",
       "      <td>d_23</td>\n",
       "      <td>d_20</td>\n",
       "      <td>d_26</td>\n",
       "      <td>d_18</td>\n",
       "      <td>d_12</td>\n",
       "      <td>d_15</td>\n",
       "      <td>d_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_2</th>\n",
       "      <td>d_17</td>\n",
       "      <td>d_4</td>\n",
       "      <td>d_10</td>\n",
       "      <td>d_3</td>\n",
       "      <td>d_19</td>\n",
       "      <td>d_8</td>\n",
       "      <td>d_12</td>\n",
       "      <td>d_20</td>\n",
       "      <td>d_23</td>\n",
       "      <td>d_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_3</th>\n",
       "      <td>d_7</td>\n",
       "      <td>d_10</td>\n",
       "      <td>d_11</td>\n",
       "      <td>d_8</td>\n",
       "      <td>d_4</td>\n",
       "      <td>d_19</td>\n",
       "      <td>d_24</td>\n",
       "      <td>d_25</td>\n",
       "      <td>d_2</td>\n",
       "      <td>d_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_4</th>\n",
       "      <td>d_11</td>\n",
       "      <td>d_17</td>\n",
       "      <td>d_19</td>\n",
       "      <td>d_8</td>\n",
       "      <td>d_3</td>\n",
       "      <td>d_2</td>\n",
       "      <td>d_23</td>\n",
       "      <td>d_24</td>\n",
       "      <td>d_13</td>\n",
       "      <td>d_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_5</th>\n",
       "      <td>d_12</td>\n",
       "      <td>d_9</td>\n",
       "      <td>d_1</td>\n",
       "      <td>d_23</td>\n",
       "      <td>d_20</td>\n",
       "      <td>d_8</td>\n",
       "      <td>d_7</td>\n",
       "      <td>d_10</td>\n",
       "      <td>d_17</td>\n",
       "      <td>d_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     top1  top2  top3  top4  top5  top6  top7  top8  top9 top10\n",
       "d_1   d_6   d_9   d_5  d_23  d_20  d_26  d_18  d_12  d_15  d_16\n",
       "d_2  d_17   d_4  d_10   d_3  d_19   d_8  d_12  d_20  d_23  d_13\n",
       "d_3   d_7  d_10  d_11   d_8   d_4  d_19  d_24  d_25   d_2  d_13\n",
       "d_4  d_11  d_17  d_19   d_8   d_3   d_2  d_23  d_24  d_13  d_25\n",
       "d_5  d_12   d_9   d_1  d_23  d_20   d_8   d_7  d_10  d_17   d_6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_rank_neighbours_matrix = find_n_neighbours(item_item_matrix,10)\n",
    "pet_rank_neighbours_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "The Pet Recommendations for User Id : 100\n",
      " \n",
      "['user' 'd_15' 'c_3']\n",
      "d_26    0.0545439\n",
      "d_16    0.0520152\n",
      "d_18    0.0519297\n",
      "c_19    0.0507271\n",
      "d_22     0.050556\n",
      "d_6     0.0505035\n",
      "c_8      0.048671\n",
      "c_13    0.0483416\n",
      "d_20    0.0472279\n",
      "d_17    0.0465327\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user=100\n",
    "user_index = user_item_matrix[user_item_matrix.user == user].index.tolist()[0]\n",
    "\n",
    "user_liked_list = user_item_matrix.loc[user_index]\n",
    "user_liked_list = user_liked_list[user_liked_list>0].index.values\n",
    "       \n",
    "#calculate the score\n",
    "ranking_score = item_item_matrix.dot(item_matrix.loc[user_index]).div(item_item_matrix.sum(axis=1))\n",
    "ranking_10_score= ranking_score.sort_values(ascending=False)\n",
    "\n",
    "print(\" \")\n",
    "print(\"The Pet Recommendations for User Id : {}\".format(user))\n",
    "print(\" \")\n",
    "\n",
    "print (user_liked_list)\n",
    "print (ranking_10_score.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
    "\n",
    "# Create a Validation Dataset\n",
    "# Split-out validation dataset\n",
    "array = user_item_matrix.values\n",
    "X = array[:,0:50]\n",
    "y = array[:,50]\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation\n",
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_validation\n",
    "Y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.939500 (0.032370)\n",
      "LDA: 0.927000 (0.024931)\n",
      "KNN: 0.903000 (0.018824)\n",
      "CART: 0.894833 (0.031802)\n",
      "NB: 0.826167 (0.081609)\n",
      "SVM: 0.903000 (0.018824)\n"
     ]
    }
   ],
   "source": [
    "# Build Models\n",
    "\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "model = SVC(gamma='auto')\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9193548387096774\n",
      "[[57  0]\n",
      " [ 5  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        57\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.92        62\n",
      "   macro avg       0.46      0.50      0.48        62\n",
      "weighted avg       0.85      0.92      0.88        62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MUICT\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\MUICT\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m   \u001b[1;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7ee63b7eeb7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_v2_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 83\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\MUICT\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d15111ad55bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create some variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"v1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"v2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Part of save model into the .ckpt file by using Tensorflow\n",
    "# Reference : https://stackoverflow.com/questions/33759623/tensorflow-how-to-save-restore-a-model\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[50], initializer = tf.zeros_initializer)\n",
    "v2 = tf.get_variable(\"v2\", shape=[50], initializer = tf.zeros_initializer)\n",
    "\n",
    "inc_v1 = v1.assign(v1+1)\n",
    "dec_v2 = v2.assign(v2-1)\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    epochs = 20\n",
    "    batch_size = 32\n",
    "\n",
    "    session.run(init)\n",
    "    # Do some work with the model.\n",
    "    inc_v1.op.run()\n",
    "    dec_v2.op.run()\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(session, \"/tmp_test/model.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-efe8b232df3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Reference : https://stackoverflow.com/questions/33759623/tensorflow-how-to-save-restore-a-model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Create some variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Reference : https://stackoverflow.com/questions/33759623/tensorflow-how-to-save-restore-a-model\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[50])\n",
    "v2 = tf.get_variable(\"v2\", shape=[50])\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"/tmp_test/model.ckpt\")\n",
    "  print(\"Model restored.\")\n",
    "  # Check the values of the variables\n",
    "  print(\"v1 : %s\" % v1.eval())\n",
    "  print(\"v2 : %s\" % v2.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://stackoverflow.com/questions/33759623/tensorflow-how-to-save-restore-a-model\n",
    "# Part of converting the .ckpt file into the .pb file\n",
    "\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "trained_checkpoint_prefix = 'tmp_test/model.ckpt'\n",
    "export_dir = os.path.join('export_dir_test', '0')\n",
    "\n",
    "graph = tf.Graph()\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore from checkpoint\n",
    "    loader = tf.train.import_meta_graph(trained_checkpoint_prefix + '.meta')\n",
    "    loader.restore(sess, trained_checkpoint_prefix)\n",
    "\n",
    "    # Export checkpoint to SavedModel\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "    builder.add_meta_graph_and_variables(sess,\n",
    "                                         [tf.saved_model.TRAINING, tf.saved_model.SERVING],\n",
    "                                         strip_default_attrs=True)\n",
    "    builder.save()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reference : https://www.tensorflow.org/lite/convert/python_api\n",
    "# Part of converting the .pb file into the .tflite file   \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "saved_model_path = \"./export_dir_test/0\"\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "tflite_model = converter.convert()\n",
    "open(\"./saved_models_test/converted_model_test.tflite\", \"wb\").write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
